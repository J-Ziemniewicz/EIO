{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evolutionary Multiple objective Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import random\n",
    "import matplotlib.pyplot as plt\n",
    "import common as cm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Benchmark  problem - discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exerciese, your are asked to implement and use an evolutionary algorithm to approximate the Pareto front of the following problem:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$min$ $\\hspace{0.5cm}$  $f_{1} = p(x)\\cdot h(x)$, <br>\n",
    "$min$ $\\hspace{0.5cm}$  $f_{2} = (1- p(x))\\cdot h(x)$,<br><br>\n",
    "where $p(x) = \\dfrac{\\sum_{j = 1}^{n} 2\\vert x_{j} - 0.5 \\vert }{n}, \\hspace{1cm} h = 1 + \\dfrac{\\sum_{j = n + 1}^{2n} \\left(2\\vert x_{j} -0.5 \\vert \\right) ^{1/\\alpha}}{n},$<br>\n",
    "$x_{j} \\in [0, 1]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'getRandomDecisionVector' method generates a random decision vector of length 2n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRandomDecisionVector(n):\n",
    "    return random.rand(1, 2 * n)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1) #TODO Finish the 'evaluate' method. Input - x = a decision vector, n - 2n = the number of decision variables, alpha - a problem-specific parameter; Output - an objective vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(x, n, alpha):\n",
    "    p = np.sum([2*abs(x[j]-0.5) for j in range(n)]) / n\n",
    "    h = 1 + np.sum([(2*abs(x[j]-0.5))**(1/alpha) for j in range(n, 2*n)]) / n\n",
    "    return [p*h, (1-p)*h]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2) The below code generates 1000 random solutions for different values of n and alpha (2n = the number of decision variables). How the distribution of solutions changes for different values of these parameters? Note that the decision vectors are drawn from a uniform distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = [1, 3, 5] # different values of n (2n = number of decision variables)\n",
    "alpha = [1.0, 5.0, 10.0] # different values of alpha\n",
    "crossed_params = [[n[int(i / 3)], alpha[i % 3]] for i in range(9)]\n",
    "decision_vectors = 1000\n",
    "PLOT_SIZE = 15 # Change this if you want to resize the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(PLOT_SIZE, PLOT_SIZE))\n",
    "\n",
    "for i, p in enumerate(crossed_params):\n",
    "    solutions = [evaluate( getRandomDecisionVector(p[0]), p[0], p[1]) for i in range(decision_vectors)]\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    cm.adjustPlot(plt, ax, solutions, \"Dec. Variables {}; Alpha {}\".format(p[0] * 2, p[1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Mutation operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1) #TODO Mutation operator is used to perturbate the decision vector. In other words, it slighly changes individuals in the population so as to explore the objective space. In this exercise, implement a simple Gaussian mutation. Start with the 'mutateValue' method. It should alter the input 'value' by adding a small value being drawn from the normal distribution with some small sigma, e.g., 0.05 (numpy.random.normal). However, the altered value may not be in the [0, 1] limits. In that case, repeat the process as long as the altered decision variable is infeasible.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutateValue(value, sigma=0.05):\n",
    "    mu = 0\n",
    "    while True:\n",
    "        mutated_value = value + np.random.normal(mu, sigma)\n",
    "        if 0 <= mutated_value <= 1:\n",
    "            return mutated_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2) Run the below code and check the possible outcomes (distributions) of the 'mutateValue' method. The three scenarios involve altering $0.25$, $0.50$, and $0.75$ values. You can modify the sigma and observe the outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [[mutateValue(0.25, sigma=0.05) for i in range(10000)], \n",
    "           [mutateValue(0.5, sigma=0.05) for i in range(10000)],\n",
    "           [mutateValue(0.75, sigma=0.05) for i in range(10000)]]\n",
    "\n",
    "plt.figure(figsize=(PLOT_SIZE, PLOT_SIZE / 3))\n",
    "for i in range(3):\n",
    "    ax = plt.subplot(1, 3, i + 1)\n",
    "    ax.set_xlim(0.0, 1.0)\n",
    "    count, bins, ignored = plt.hist(samples[i], 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3) #TODO finish the 'mutateVector' method. It should perturbate the input decision vector and return a new, modified one. For this reason, use the 'mutateValue' method (pass 'sigma' parameter). In this exercise, randomly decide whether to mutate a decision variable or not. Specifically, set the probability of altering a decision variable to 'probability' (method's argument)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutateVector(decision_vector, probability, sigma = 0.05):\n",
    "    mutated_vector = []\n",
    "    for i in decision_vector:\n",
    "        if np.random.uniform() <= probability:\n",
    "            mutated_vector.append(mutateValue(i, sigma))\n",
    "        else:\n",
    "            mutated_vector.append(i)\n",
    "    return mutated_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4) Run the below code (observe the value of 'probability'). The generated plots illustrate some original solutions (red dots) being altered $1000$ times (black dots). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(PLOT_SIZE, PLOT_SIZE))\n",
    "\n",
    "for i, p in enumerate(crossed_params):\n",
    "    probability = 1.0 / (p[0] * 2)\n",
    "    main_vector = [0.25 for i in range(p[0] * 2)]\n",
    "    main_solution = evaluate(main_vector, p[0], p[1])\n",
    "    solutions = [ evaluate(mutateVector(main_vector, probability, sigma = 0.05), p[0], p[1]) for i in range(decision_vectors) ]\n",
    "    \n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    cm.adjustPlot(plt, ax, solutions, \"Dec. Variables {}; Alpha {}\".format(p[0] * 2, p[1]))\n",
    "    plt.plot(main_solution[0], main_solution[1], marker='o', linestyle='', markersize=5, mfc = 'red' ,mec='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Crossover operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1) #TODO Crossover operator combines two decision vectors to generate offspring, which is expected to possess the best features of its parents. Implement the 'crossoverTwoVectors' method which returns a new decision vector. Set each i-th element of the new vector to some random convex combination of the i-th values of dv1 and dv2 (decision vectors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossoverTwoVectors(dv1, dv2):\n",
    "    offspring = []\n",
    "    for first, second in zip(dv1, dv2):\n",
    "        weight = np.random.uniform()\n",
    "        offspring.append(weight * first + (1-weight) * second)\n",
    "    return offspring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2) Run the below code. The generated plots illustrate some original parent solutions (red dot) being combined $1000$ times (black dots). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(PLOT_SIZE, PLOT_SIZE))\n",
    "\n",
    "for i, p in enumerate(crossed_params):\n",
    "    main_vector1 = [0.35 for i in range(p[0])] + [0.6 for i in range(p[0])]\n",
    "    main_solution1 = evaluate(main_vector1,p[0], p[1])\n",
    "    main_vector2 = [0.15 for i in range(p[0])] + [0.8 for i in range(p[0])]\n",
    "    main_solution2 = evaluate(main_vector2, p[0], p[1])\n",
    "    solutions = [ evaluate(crossoverTwoVectors(main_vector1, main_vector2),p[0], p[1]) for i in range(decision_vectors) ]\n",
    "    ### PLOT IT \n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    cm.adjustPlot(plt, ax, solutions, \"Dec. Variables {}; Alpha {}\".format(p[0] * 2, p[1]))\n",
    "    plt.plot(main_solution1[0], main_solution1[1], marker='o', linestyle='', markersize=5, mfc = 'red' ,mec='red')\n",
    "    plt.plot(main_solution2[0], main_solution2[1], marker='o', linestyle='', markersize=5, mfc = 'red' ,mec='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3) Run the below code and observe new solutions being generated by means of combined crossover and mutation operators. You can alter 'sigma' and 'probability' to observe which solutions would be generated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(PLOT_SIZE, PLOT_SIZE))\n",
    "\n",
    "for i, p in enumerate(crossed_params):\n",
    "    main_vector1 = [0.35 for i in range(p[0])] + [0.6 for i in range(p[0])]\n",
    "    main_solution1 = evaluate(main_vector1,p[0], p[1])\n",
    "    main_vector2 = [0.15 for i in range(p[0])] + [0.8 for i in range(p[0])]\n",
    "    main_solution2 = evaluate(main_vector2, p[0], p[1])\n",
    "    ### MODIFY HERE #############\n",
    "    probability = 1.0 / (p[0] * 2)\n",
    "    sigma = 0.05\n",
    "    #############################\n",
    "    solutions = [ evaluate(mutateVector(crossoverTwoVectors(main_vector1, main_vector2), probability = probability \\\n",
    "                                        , sigma=sigma), p[0], p[1]) for i in range(decision_vectors) ]\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    cm.adjustPlot(plt, ax, solutions, \"Dec. Variables {}; Alpha {}\".format(p[0] * 2, p[1]))\n",
    "    plt.plot(main_solution1[0], main_solution1[1], marker='o', linestyle='', markersize=5, mfc = 'red' ,mec='red')\n",
    "    plt.plot(main_solution2[0], main_solution2[1], marker='o', linestyle='', markersize=5, mfc = 'red' ,mec='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Evolutionary Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1) Now, your task is to implement a simple evolutionary algorithm for multiple objective optimization. Use the following scheme: <br> <br>\n",
    "    1] $P$ = create an initial population of size $N$ <br>\n",
    "    2] $AssignFitness(P)$ <br>\n",
    "    3] Sort $P$ according to fitness <br>\n",
    "    4] $M$ = Generate a mating pool (list of pairs of parent solutions) <br>\n",
    "    5] $O$ = Apply genetic operators to $M$ in order to generate offspring $O$ of size $N$ <br>\n",
    "    6] $AssignFitness(O)$ <br>\n",
    "    7] $P' = P \\cup O$ ($|P'| = 2N$) <br>\n",
    "    8] Sort $P'$ according to fitness <br>\n",
    "    9] $P$ = first $N$ solutions in $P'$ (survival of the fittest) <br>\n",
    "    10] Go back to $[4]$ if the stopping criterion is not satisfied\n",
    "    \n",
    "The above process is described in details in emo.pdf.\n",
    "    \n",
    "In the following, you will implement some auxiliary methods, e.g., getInitialPopulation (see the above scheme). Finally, you will implement the evolutionary algorithm, using the implemented methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2) Acquaint yourself with the following class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Solution:\n",
    "    # dv = decision vector\n",
    "    # 2n = number of decision variables\n",
    "    def __init__(self, dv, n):\n",
    "        self.decision_vector = dv\n",
    "        self.objective_vector = evaluate(dv, n, alpha)\n",
    "        self.fitness = 0.0\n",
    "        \n",
    "    # if true: this solution dominates 'otherSolution'\n",
    "    def dominates(self, otherSolution):\n",
    "        if (self.objective_vector[0] < otherSolution.objective_vector[0]) and \\\n",
    "        (self.objective_vector[1] <= otherSolution.objective_vector[1]):\n",
    "            return True\n",
    "        if (self.objective_vector[0] <= otherSolution.objective_vector[0]) and \\\n",
    "        (self.objective_vector[1] < otherSolution.objective_vector[1]):\n",
    "            return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.3) #TODO Finish the below method. It should create, and return, an initial population consisting of N solutions being generated randomly (2n = the number of decision variables) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInitialPopulation(N, n):\n",
    "    population = []\n",
    "    for i in range(N):\n",
    "        population.append(Solution(getRandomDecisionVector(n), n))\n",
    "    return population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.4) #TODO Finish the two below methods. The 'getNonDominatedFronts' method should partition solutions into non-dominated fronts. The method is expected to return a list of the following form: [[IDs of non-dominated solutions], [IDs of solutions in the second non-dominated front],...,[IDs of solutions in the last non-dominated front]. For instance: [[0, 2, 5], [3, 4], [1]] (ID = 0 <-> population[0]). Then, assign the solutions' fitness in the 'assignFitness' method (the first front = the fitness of 0, the second front = the fitness of 1, and so on)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_not_dominated(solution, population, not_sorted_IDs):\n",
    "    for other in not_sorted_IDs:\n",
    "        if population[other].dominates(solution):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def getNonDominatedFronts(population):\n",
    "    fronts = []\n",
    "    not_sorted_IDs = list(range(len(population))) #lista z indeksami, jest tu po to żeby z niej usuwać przydzielone elementy nie ruszając porządku we właściwej populacji\n",
    "    \n",
    "    while len(not_sorted_IDs) > 0:\n",
    "        front = []\n",
    "        for ID in not_sorted_IDs:\n",
    "            if is_not_dominated(population[ID], population, not_sorted_IDs):\n",
    "                front.append(ID)\n",
    "        not_sorted_IDs = [x for x in not_sorted_IDs if x not in front] #remove assigned to this front from not sorted set\n",
    "        fronts.append(front)\n",
    "    \n",
    "    return fronts\n",
    "\n",
    "def assignFitness(population):\n",
    "    fronts = getNonDominatedFronts(population)\n",
    "    for fit, front in enumerate(fronts):\n",
    "        for i in front:\n",
    "            population[i].fitness = fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.5) #TODO Finish the below method. It should sort the input list (population) in ascending order (the best solutions should be contained in the beggining of the list). Use 'fitness' as the key. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortSolutions(population):\n",
    "    population.sort(key=lambda x: x.fitness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.6) #TODO Finish the below code. N new solutions have to be generated every generation. For these reason, parents must be selected (getMatingPool) and then recombined. To select parent solutions, implement a simple tournament selection of size two. Assuming that the solutions are sorted from the most to the least preferred, the tournament selection of size 2 randomly draws 2 solutions and chooses the one having the best (smallest) rank. Use this procedure to build a mating pool of the following form [[PARENT1, PARENT2], [PARENT3, PARENT4],...,[PARENT(2N-1), PARENT(2N)]]. Each two parents (e.g., 1 and 2) will be used to generated a single offspring solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_parent(population, tournament_size=2):\n",
    "    idx = np.min(np.random.randint(0, len(population), size=tournament_size))\n",
    "    return population[idx]\n",
    "\n",
    "def getMatingPool(population, N):\n",
    "    mating_pool = []\n",
    "    for i in range(N):\n",
    "        mating_pool.append([select_parent(population), select_parent(population)])\n",
    "    return mating_pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.7) #TODO Finish the below code. Use the 'crossoverTwoVectors' and 'mutateVector' methods to recombine parent solutions and construct an offspring population of size N. Set 'sigma' to 0.05 and 'probability' to 1/(2n). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createOffspring(mating_pool, N, n):\n",
    "    offspring_population = []\n",
    "    for parents in mating_pool:\n",
    "        offspring = crossoverTwoVectors(parents[0].decision_vector, parents[1].decision_vector)\n",
    "        offspring = mutateVector(offspring, probability=(1/(2*n)), sigma=0.05)\n",
    "        offspring_population.append(Solution(offspring, n))\n",
    "    return offspring_population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.8) #TODO Finish the below code. It should concatenate 'population' and 'offspring' and return a combined population of size 2N."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergePopulations(population, offspring):\n",
    "    return population + offspring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.9) #TODO Finish the below code. It should return a list of the N-best solutions in the input population (it is assumed that the solutions are already sorted from the most to the least preffered, according to fitness). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def survivalOfTheFittest(merged, N):\n",
    "    return merged[:N]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.10) Now, it is time to combine the above methods and implement an evolutionary algorithm for multiple objective optimization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some params\n",
    "N = 50 # population size\n",
    "n = 3 # 2n = number of decision variables\n",
    "alpha = 5.0 # problem-specific parameter\n",
    "PLOT_EVERY = 50 # plot every 'PLOT_EVERY' generations\n",
    "generations = 8 * PLOT_EVERY # the total number of generations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.11) #TODO Implement the algorithm here. Use the above implmented methods and follow the scheme provided in point 4.1. Furthermore, capture the 'snapshots' of constructed populations (see the below comment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNAPSHOTS = []\n",
    "\n",
    "# Create an initial population\n",
    "random_population = getInitialPopulation(N, n)\n",
    "# Assign fitness\n",
    "assignFitness(population=random_population)\n",
    "# Sort solutions\n",
    "sortSolutions(random_population)\n",
    "# Repeat for 'generations' iterations\n",
    "population = random_population\n",
    "for generation in range(generations):\n",
    "    # -- Construct a mating pool\n",
    "    mating_pool = getMatingPool(population, N)\n",
    "    # -- Generate an offspring population\n",
    "    offspring_population = createOffspring(mating_pool, N, n)\n",
    "    # -- Create a combined population (parents + offspring)\n",
    "    combined_population = mergePopulations(population, offspring_population)\n",
    "    # -- Assign fitness (combined population)\n",
    "    assignFitness(combined_population)\n",
    "    # -- Sort solutions (combined population)\n",
    "    sortSolutions(combined_population)\n",
    "    # -- Set the current population to N-best memberd of the merged population\n",
    "    population = survivalOfTheFittest(combined_population, N)\n",
    "    # -- Capture snapshots\n",
    "    ### Use the following code to capture (and display later) populations constructed after 1, 1/8*generations,\n",
    "    # 2/8*generations,..., generations.\n",
    "    if ((generation + 1) % PLOT_EVERY == 0) or generation == 0:\n",
    "        SNAPSHOTS.append(population.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.12) Run the below code and observe how the population moves towards the Pareto front. However, the distribution of solutions in the final population is poor. Most of them are concentrated around the middle of the Pareto front. Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm.displaySnapshots(plt, PLOT_EVERY, PLOT_SIZE, SNAPSHOTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.13) #TODO Copy & paste the above finished algotihm. This time, hovewer, compute the GD and IGD the population attains in each generation. Use cm.getGenerationalDistance(some population) and cm.getInvertedGenerationalDistance(some population, N). Append the results to GD and IGD lists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GD = []\n",
    "IGD = []\n",
    "\n",
    "# Create an initial population\n",
    "random_population = getInitialPopulation(N, n)\n",
    "# Assign fitness\n",
    "assignFitness(population=random_population)\n",
    "# Sort solutions\n",
    "sortSolutions(random_population)\n",
    "# Repeat for 'generations' iterations\n",
    "population = random_population\n",
    "for generation in range(generations):\n",
    "    # -- Construct a mating pool\n",
    "    mating_pool = getMatingPool(population, N)\n",
    "    # -- Generate an offspring population\n",
    "    offspring_population = createOffspring(mating_pool, N, n)\n",
    "    # -- Create a combined population (parents + offspring)\n",
    "    combined_population = mergePopulations(population, offspring_population)\n",
    "    # -- Assign fitness (combined population)\n",
    "    assignFitness(combined_population)\n",
    "    # -- Sort solutions (combined population)\n",
    "    sortSolutions(combined_population)\n",
    "    # -- Set the current population to N-best memberd of the merged population\n",
    "    population = survivalOfTheFittest(combined_population, N)\n",
    "\n",
    "    GD.append(cm.getGenerationalDistance(population))\n",
    "    IGD.append(cm.getInvertedGenerationalDistance(population, N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.14) Run the below code and observe how GD and IGD changed over time. Repeat the simulation several times. You should observe that, usually, the attained GD was better (lesser) than IGD attained in the end of the optimization run. In turn, IGD was better in the beggining. Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm.plotQualityIndicators(plt, GD, IGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.    4.0 for completing this assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.1) #TODO Now, improve the algorithm by applying the crowding-distance to favour well-distributed solutions in the course of the optimization. Complete the below code. Firstly, use 'getNonDominatedFronts' to partition the solutions into non-dominance fronts and set the solutions' fitness. Then, for each front, compute solutions' crowding-distance value and update their fitness (normalize the crowding-distance value such that it fits the limits of [0, 1) )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zwraca odwrotność, więc mniejsze wartości będą lepsze\n",
    "#jest tak dlatego, że potem ta wartość (po normalizacji) jest dodawana do fitness\n",
    "#a fitness im mniejszy tym lepszy\n",
    "def calculate_crowding_distance(previous_neighbor, next_neighbor, x_range, y_range):\n",
    "    x = (previous_neighbor.objective_vector[0] - next_neighbor.objective_vector[0]) / x_range\n",
    "    y = (next_neighbor.objective_vector[1] - previous_neighbor.objective_vector[1]) / y_range\n",
    "    if not (x > 0 or y > 0): #jeśli są (niemal)identyczne, to zwróć najgorszą wartość, taka \"odwrotność zera\"\n",
    "        return 99999999\n",
    "    return 1 / ((x + y) / 2)\n",
    "\n",
    "def normalize_crowding_distances(crowding_distances):\n",
    "    divisor = max(crowding_distances) + 0.01 #żeby się zmieściło w [0,1)\n",
    "    for i in range(len(crowding_distances)):\n",
    "        crowding_distances[i] /= divisor\n",
    "    \n",
    "\n",
    "def assignFitnessWithCrowding(population):\n",
    "    fronts = getNonDominatedFronts(population)\n",
    "    assignFitness(population)\n",
    "    for front in fronts:\n",
    "        front_solutions = [population[i] for i in front]\n",
    "        front_solutions.sort(key=lambda x: (x.objective_vector[0], x.objective_vector[1]), reverse=True)\n",
    "        crowding_distances = []\n",
    "        \n",
    "        crowding_distances.append(0)#skrajny element\n",
    "        x_min = min(front_solutions, key=lambda x : x.objective_vector[0]).objective_vector[0]\n",
    "        x_max = max(front_solutions, key=lambda x : x.objective_vector[0]).objective_vector[0]\n",
    "        y_min = min(front_solutions, key=lambda x : x.objective_vector[1]).objective_vector[1]\n",
    "        y_max = max(front_solutions, key=lambda x : x.objective_vector[1]).objective_vector[1]\n",
    "        x_range = x_max - x_min\n",
    "        y_range = y_max - y_min\n",
    "        for i in range(1, len(front_solutions)-1):\n",
    "            crowding_distances.append(calculate_crowding_distance(front_solutions[i-1], front_solutions[i+1], x_range, y_range))\n",
    "        crowding_distances.append(0)#skrajny element\n",
    "        \n",
    "        normalize_crowding_distances(crowding_distances)\n",
    "        for i in range(len(front_solutions)):\n",
    "            front_solutions[i].fitness += crowding_distances[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2) #TODO Copy & paste the algorithm you have finished in step 4.12. This time, use assignFitnessWithCrowding method. Run the below pieces of code. Observe the plots. Have the results improved? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "SNAPSHOTS = []\n",
    "GD = []\n",
    "IGD = []\n",
    "\n",
    "# Create an initial population\n",
    "random_population = getInitialPopulation(N, n)\n",
    "# Assign fitness\n",
    "assignFitness(population=random_population)\n",
    "# Sort solutions\n",
    "sortSolutions(random_population)\n",
    "# Repeat for 'generations' iterations\n",
    "population = random_population\n",
    "for generation in range(generations):\n",
    "    # -- Construct a mating pool\n",
    "    mating_pool = getMatingPool(population, N)\n",
    "    # -- Generate an offspring population\n",
    "    offspring_population = createOffspring(mating_pool, N, n)\n",
    "    # -- Create a combined population (parents + offspring)\n",
    "    combined_population = mergePopulations(population, offspring_population)\n",
    "    # -- Assign fitness (combined population)\n",
    "    assignFitnessWithCrowding(combined_population)\n",
    "    # -- Sort solutions (combined population)\n",
    "    sortSolutions(combined_population)\n",
    "    # -- Set the current population to N-best memberd of the merged population\n",
    "    population = survivalOfTheFittest(combined_population, N)\n",
    "    \n",
    "    GD.append(cm.getGenerationalDistance(population))\n",
    "    IGD.append(cm.getInvertedGenerationalDistance(population, N))\n",
    "    \n",
    "    # -- Capture snapshots\n",
    "    ### Use the following code to capture (and display later) populations constructed after 1, 1/8*generations,\n",
    "    # 2/8*generations,..., generations.\n",
    "    if ((generation + 1) % PLOT_EVERY == 0) or generation == 0:\n",
    "        SNAPSHOTS.append(population.copy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm.displaySnapshots(plt, PLOT_EVERY, PLOT_SIZE, SNAPSHOTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm.plotQualityIndicators(plt, GD, IGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 5.0 for completing this assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.1) #TODO The results which are derived from a single optimization run are not credible as the evolutionary algorithms are susceptible to some random fluctuations. In this exercise, you are asked to compute the GD and IGD averaged over 10 independent runs. Then, plot the mean and std values of GD and IGD (see, e.g., this plot http://www.randalolson.com/wp-content/uploads/chess-piece-capture-rate-over-time.png). Use e.g., plt.fill_between."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_algorithm(GD, IGD):\n",
    "    # Create an initial population\n",
    "    random_population = getInitialPopulation(N, n)\n",
    "    # Assign fitness\n",
    "    assignFitness(population=random_population)\n",
    "    # Sort solutions\n",
    "    sortSolutions(random_population)\n",
    "    # Repeat for 'generations' iterations\n",
    "    population = random_population\n",
    "    for generation in range(generations):\n",
    "        # -- Construct a mating pool\n",
    "        mating_pool = getMatingPool(population, N)\n",
    "        # -- Generate an offspring population\n",
    "        offspring_population = createOffspring(mating_pool, N, n)\n",
    "        # -- Create a combined population (parents + offspring)\n",
    "        combined_population = mergePopulations(population, offspring_population)\n",
    "        # -- Assign fitness (combined population)\n",
    "        assignFitnessWithCrowding(combined_population)\n",
    "        # -- Sort solutions (combined population)\n",
    "        sortSolutions(combined_population)\n",
    "        # -- Set the current population to N-best memberd of the merged population\n",
    "        population = survivalOfTheFittest(combined_population, N)\n",
    "\n",
    "        GD[generation] = cm.getGenerationalDistance(population)\n",
    "        IGD[generation] = cm.getInvertedGenerationalDistance(population, N)\n",
    "\n",
    "        # -- Capture snapshots\n",
    "        ### Use the following code to capture (and display later) populations constructed after 1, 1/8*generations,\n",
    "        # 2/8*generations,..., generations.\n",
    "        if ((generation + 1) % PLOT_EVERY == 0) or generation == 0:\n",
    "            SNAPSHOTS.append(population.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_RUNS = 10\n",
    "\n",
    "GD = np.zeros([TEST_RUNS, generations])\n",
    "IGD = np.zeros([TEST_RUNS, generations])\n",
    "\n",
    "for i in range(TEST_RUNS):\n",
    "    print(\"Run\", i)\n",
    "    run_algorithm(GD[i], IGD[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Compute averaged statistics here\n",
    "\n",
    "MEAN_GD = np.mean(GD, axis=0)\n",
    "STD_GD = np.std(GD, axis=0)\n",
    "\n",
    "MEAN_IGD = np.mean(IGD, axis=0)\n",
    "STD_IGD = np.std(IGD, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(generations)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(x, MEAN_GD, label=\"GD\")\n",
    "plt.fill_between(x, MEAN_GD-STD_GD, MEAN_GD+STD_GD, facecolor='#78caff')\n",
    "\n",
    "plt.plot(x, MEAN_IGD, label=\"IGD\")\n",
    "plt.fill_between(x, MEAN_IGD-STD_IGD, MEAN_IGD+STD_IGD, facecolor='#ffc89e')\n",
    "\n",
    "plt.xlabel(\"generation\")\n",
    "plt.ylabel(\"quality\")    \n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
